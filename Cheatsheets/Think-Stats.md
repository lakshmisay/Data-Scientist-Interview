# Think Stats
## Chapter 1 - Statistical thinking for programmers
* **anecdotal evidence**: Evidence, often personal, that is collected casually rather than by a well-designed study.
* **population**: A group we are interested in studying.
* **cross-sectional study**: A study that collects data about a population at a particular point in time.
* **longitudinal study**: A study that follows a population over time, collecting data from the same group repeatedly.
* **respondent**: A person who responds to a survey.
* **cohort**: A group of respondents.
* **sample**: The subset of a population used to collect data.
* **representative**: A sample is representative if every member of the population has the same chance of being in the sample.
* **oversampling**: The technique of increasing the representation of a sub-population in order to avoid errors due to small sample sizes.
* **record**: In a database, a collection of information about a single person or other object of study.
* **field**: In a database, one of the named variables that makes up a record.
* **table**: In a database, a collection of records.
* **raw data**: Values collected and recorded with little or no checking, calculation or interpretation.
* **recode**: A value that is generated by calculation and other logic applied to raw data.
* **summary statistic**: The result of a computation that reduces a dataset to a single number that captures some characteristic of the data.
* **apparent effect**: A measurement or summary statistic that suggests that something interesting is happening.
* **statistically significant**: An apparent effect is statistically significant if it is unlikely to occur by chance.
* **artifact**: An apparent effect that is caused by bias, measurement error, or some other kind of error.

## Chapter 2 - Descriptive statistics
* **central tendency**: A characteristic of a sample or population; intuitively, it is the most average value.
* **spread**: A characteristic of a sample or population; intuitively, it describes how much variability there is.
* **variance**: A summary statistic often used to quantify spread.
* **standard deviation**: The square root of variance, also used as a measure of spread.
* **frequency**: The number of times a value appears in a sample.
* **histogram**: A mapping from values to frequencies, or a graph that shows this mapping.
* **probability**: A frequency expressed as a fraction of the sample size.
* **normalization**: The process of dividing a frequency by a sample size to get a probability.
* **distribution**: A summary of the values that appear in a sample and the frequency, or probability, of each.
* **PMF**: Probability mass function - a representation of a distribution as a function that maps from values to probabilities.
* **mode**: The most frequent value in a sample.
* **outlier**: A value far from the central tendency.
* **trim**: To remove outliers from a dataset.
* **bin**: A range used to group nearby values.
* **relative risk**: A ratio of 2 probabilities, often used to measure a difference between distributions.
* **conditional probability**: A probability computed under the assumption that some condition holds.
* **clinically significant**: A result, like a difference between groups, that is relevant in practice.

## Chapter 3 - Cumulative distribution functions
* **percentile rank**: The percentage of values in a distribution that are less than or equal to a given value.
* **CDF**: Cumulative distribution function - a function that maps from values to their percentile ranks.
* **percentile**: The value associated with a given percentile rank.
* **conditional distribution**: A distribution computed under the assumption that some condition holds.
* **resampling**: The process of generating a random sample from a distribution that was computed from a sample.
* **replacement**: During a sampling process, "replacement" indicates that the population is the same for every sample. "Without replacement" indicates that each element can be selected only once.
* **interquartile range**: A measure of spread, the difference between the 75th and 25th percentiles.

## Chapter 4 - Continuous distributions
* **empirical distribution**: The distribution of values in a sample.
* **continuous distribution**: A distribution described by a continuous function.
* **interarrival time**: The elapsed time between two events.
* **error function**: A special mathematical function, so-named because it comes up in the study of measurement errors.
* **normal probability plot**: A plot of the sorted values in a sample versus the expected value for each if their distribution is normal.
* **rankit**: The expected value of an element in a sorted list of values from a normal distribution.
* **model**: A useful simplification. Continuous distributions are often good models of more complex empirical distributions.
* **corpus**: A body of text used as a sample of a language.
* **hapaxlegomenon**: A word that appears only once in a corpus.

## Chapter 5 - Probability
* **event**: Something that may or may not occur, with some probability.
* **trial**: One in a series of occasions when an event might occur.
* **success**: A trial in which an event occurs.
* **failure**: A trial in which no event occurs.
* **frequentism**: A strict interpretation of probability that only applies to a series of identical trials.
* **Bayesianism**: A more general interested that uses probability to represent a subjective degree of belief.
* **independent**: Two events are independent if the occurrence of one does has no effect on the probability of another.
* **coefficient of variation**: A statistic that measures spread, normalized by central tendency, for comparison between distributions with different means.
* **Monte Carlo simulation**: A method of computing probabilities by simulating random processes.
* **update**: The process of using data to revise a probability.
* **prior**: A probability before a Bayesian update.
* **posteror**: A probability computed by a Bayesian update.
* **likelihood of the evidence**: One of the terms in Bayes's theorem, the probability of the evidence conditioned on a hypothesis.
* **normalizing constant**: The denominator of Bayes's theorem, used to normalize the result to be a probability.

## Chapter 6 - Operations on distributions
* **skewness**: A characteristic of a distribution; intuitively, it is a measure of how asymmetric the distribution is.
* **robust**: A statistic is robust if it is relatively immune to the effect of outliers.
* **illusory superiority**: The tendency of people to imagine that they are better than average.
* **random variable**: An object that represents a random process.
* **random variate**: A value generated by a random process.
* **PDF**: Probability density function - the derivative of a continuous CDF.
* **convolution**: An operation that computes the distribution of the sum of values from two distributions.
* **Central Limit Theorem**: "The supreme law of Unreason."

## Chapter 7 - Hypothesis testing
* **significant**: An effect is statistically significant if it is unlikely to occur by chance.
* **null hypothesis**: A model of a system based on the assumption that an apparent effect is due to chance.
* **p-value**: The probability that an effect could occur by chance.
* **hypothesis testing**: The process of determining whether an apparent effect is statistically significant.
* **false positive**: The conclusion that an effect is real when it is not.
* **false negative**: The conclusion that an effect is due to chance when it is not.
* **two-sided test**: A test that asks, "What is the chance of an effect as big as the observed effect, positive or negative?"
* **one-sided test**: A test that asks, "What is the chance of an effect as big as the observed effect, and with the same sign?"
* **cross-validation**: A process of hypothesis testing that uses one dataset for EDA and another dataset for testing.
* **training set**: A dataset used to formulate a hypothesis for testing.
* **testing set**: A dataset used for testing.
* **test statistic**: A statistic used to measure the deviation of an apparent effect from what is expected by chance.
* **chi-square test**: A test that uses the chi-square statistic as the test statistic.
* **likelihood ratio**: The ratio of P(E | A) to P(E | B) for two hypotheses A and B, which is a way to report results from a Bayesian analysis without depending on priors.
* **cell**: In a chi-square test, the categories the observations are divided into.
* **power**: The probability that a test will reject the null hypothesis if it is false.

## Chapter 8 - Estimation
* **estimation**: The process of inferring the parameters of a distribution from a sample.
* **estimator**: A statistic used to estimate a parameter.
* **mean squared error**: A measure of estimation error.
* **maximum likelihood estimator**: An estimator that computes the point estimate with the highest likelihood.
* **bias**: The tendency of an estimator to be above or below the actual value of the parameter, when averaged over repeated samples.
* **point estimate**: An estimate expressed as a single value.
* **confidence interval**: An estimate expressed as an interval with a given probability of containing the true value of the parameter.
* **credible interval**: Another name of a Bayesian confidence interval.
* **censored data**: A dataset sampled in a way that systematically excludes some data.

## Chapter 9 - Correlation
* **correlation**: A description of the dependence between variables.
* **normalize**: To transform a set of values so that their mean is 0 and their variance is 1.
* **standard score**: A value that has been normalized.
* **covariance**: A measure of the tendency of two variables to vary together.
* **rank**: The index where an element appears in a sorted list.
* **least squares fit**: A model of a dataset that minimizes the sum of squares of the residuals.
* **residual**: A measure of the deviation of an actual value from a model.
* **dependent variable**: A variable we are trying to predict or explain.
* **independent variable**: A variable we are using to predict a dependent variable (also called an explanatory variable).
* **coefficient of determination**: A measure of the goodness of fit of a linear model.
* **randomized controlled trial**: An experimental design in which subject are divided into groups at random, and different groups are given different treatments.
* **treatment**: A change or intervention applied to one group in a controlled trial.
* **control group**: A group in a controlled trial that receives no treatment, or a treatment whose effect is known.
* **natural experiment**: An experimental design that takes advantage of a natural division of subjects into groups in ways that are at least approximately random.
